---
layout: post
title: A minimally viable machine learning service
---

A canonical virtue of science and engineering is simplicity. Between two theories that explain a phenomenon equally well, a scientist chooses the simpler one. Why? 
Occam's razor says not to "multiply causes", and its 20th century [Bayesian formalization](http://mlg.eng.cam.ac.uk/zoubin/papers/05occam/occam.pdf) says that hypotheses that are "hard to vary" are preferred. I borrow the "hard to vary" phrase from David Deutsch, who builds his epistemology on this principle (see [this TED talk](https://www.ted.com/talks/david_deutsch_a_new_way_to_explain_explanation) for a quick exposition). 

For years, I didn't fully appreciate the other great benefit of simplicity, which is that simple things are easier to build and maintain. My supervisor instructed me to always cut things down to their essence, to break problems down to their smallest components (as in the very word "analysis"). And yet simplifying things is somehow so counter-intuitive that I must constantly remind myself to do it.

My PhD project is called "Machine Learning as a Service", or MLaaS for short. I'm supposed to 